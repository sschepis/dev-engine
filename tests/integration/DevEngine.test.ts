// =============================================================================
// OpenClaw DevEngine - Integration Tests (with Mocked Services)
// =============================================================================

import { describe, it, expect, beforeEach, jest } from '@jest/globals';
import { DevEngine } from '../../src/core/DevEngine.js';
import { createMockAdapter, MockEnvironmentAdapter } from '../mocks/adapters.js';
import { SkillContext } from '../../src/interfaces/index.js';

describe('DevEngine Integration', () => {
  let mockAdapter: MockEnvironmentAdapter;
  let engine: DevEngine;

  beforeEach(() => {
    mockAdapter = createMockAdapter();
    engine = new DevEngine(mockAdapter, {
      maxConcurrency: 2,
      maxRetries: 2,
      enableCheckpoints: false,  // Disable for faster tests
      verbose: false
    });

    // Configure default LLM responses
    setupDefaultLLMResponses();
  });

  function setupDefaultLLMResponses() {
    // Architect response
    mockAdapter.llm.addPromptMatch('Lead System Architect', JSON.stringify({
      architecture_reasoning: 'Simple architecture for testing',
      tasks: [
        {
          id: 'main-module',
          file_path: 'src/main.ts',
          description: 'Main module implementation',
          dependencies: [],
          type: 'code',
          priority: 10
        },
        {
          id: 'main-test',
          file_path: 'src/main.test.ts',
          description: 'Tests for main module',
          dependencies: ['main-module'],
          type: 'test',
          priority: 5
        }
      ]
    }));

    // Builder response
    mockAdapter.llm.addPromptMatch('Senior TypeScript Developer', `
export function greet(name: string): string {
  return \`Hello, \${name}!\`;
}

export function add(a: number, b: number): number {
  return a + b;
}
`);

    // Auditor response
    mockAdapter.llm.addPromptMatch('QA Automation Engineer', `
import { greet, add } from './main.js';

describe('Main module', () => {
  it('should greet correctly', () => {
    expect(greet('World')).toBe('Hello, World!');
  });

  it('should add numbers', () => {
    expect(add(2, 3)).toBe(5);
  });
});
`);

    // Scribe response
    mockAdapter.llm.addPromptMatch('Technical Writer', `
# Test Project

A simple test project generated by DevEngine.

## Installation

\`\`\`bash
npm install
\`\`\`

## Usage

\`\`\`typescript
import { greet, add } from './main.js';

console.log(greet('World'));
console.log(add(2, 3));
\`\`\`
`);

    // Configure test runner to pass
    mockAdapter.shell.setTestResult('src/main.test.ts', {
      passed: true,
      numPassed: 2,
      numFailed: 0,
      rawOutput: 'PASS src/main.test.ts'
    });
  }

  describe('manifest', () => {
    it('should have correct manifest structure', () => {
      expect(engine.manifest.id).toBe('openclaw.dev-engine');
      expect(engine.manifest.version).toBe('2.0.0');
      expect(engine.manifest.requires.llm).toBe(true);
      expect(engine.manifest.requires.filesystem).toBe(true);
      expect(engine.manifest.requires.shell).toBe(true);
    });
  });

  describe('execute() - ISkill interface', () => {
    it('should execute successfully with valid context', async () => {
      const context: SkillContext = {
        adapter: mockAdapter,
        parameters: {
          goal: 'Create a simple greeting function'
        },
        workingDirectory: '/test'
      };

      const result = await engine.execute(context);

      expect(result.success).toBe(true);
      expect(result.output).toContain('complete');
      expect(result.artifacts).toContain('src/main.ts');
    });

    it('should return error result on failure', async () => {
      // Clear previous responses and set invalid JSON as default
      mockAdapter.llm.reset();
      mockAdapter.llm.setResponse('Invalid JSON {{{');

      const context: SkillContext = {
        adapter: mockAdapter,
        parameters: {
          goal: 'Create something that will fail'
        },
        workingDirectory: '/test'
      };

      const result = await engine.execute(context);

      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });
  });

  describe('validate()', () => {
    it('should validate required parameters', async () => {
      const context: SkillContext = {
        adapter: mockAdapter,
        parameters: {},  // Missing goal
        workingDirectory: '/test'
      };

      const errors = await engine.validate!(context);

      expect(errors).toContain('Parameter "goal" is required and must be a string');
    });

    it('should pass with valid parameters', async () => {
      const context: SkillContext = {
        adapter: mockAdapter,
        parameters: { goal: 'Valid goal' },
        workingDirectory: '/test'
      };

      const errors = await engine.validate!(context);

      expect(errors).toHaveLength(0);
    });
  });

  describe('estimateCost()', () => {
    it('should estimate token usage', async () => {
      const context: SkillContext = {
        adapter: mockAdapter,
        parameters: { goal: 'A simple goal' },
        workingDirectory: '/test'
      };

      const estimate = await engine.estimateCost!(context);

      expect(estimate.tokens).toBeGreaterThan(0);
      expect(estimate.cost).toBeGreaterThan(0);
    });

    it('should estimate higher for complex goals', async () => {
      const simpleContext: SkillContext = {
        adapter: mockAdapter,
        parameters: { goal: 'Simple' },
        workingDirectory: '/test'
      };

      const complexContext: SkillContext = {
        adapter: mockAdapter,
        parameters: { 
          goal: 'A very complex goal with many requirements including authentication, database integration, API endpoints, caching, and comprehensive testing' 
        },
        workingDirectory: '/test'
      };

      const simpleEstimate = await engine.estimateCost!(simpleContext);
      const complexEstimate = await engine.estimateCost!(complexContext);

      expect(complexEstimate.tokens).toBeGreaterThan(simpleEstimate.tokens);
    });
  });

  describe('run()', () => {
    it('should execute full development workflow', async () => {
      const result = await engine.run('Create a greeting module');

      expect(result).toContain('complete');
      
      // Should have written source file
      const sourceContent = mockAdapter.fs.getWrittenContent('src/main.ts');
      expect(sourceContent).toBeDefined();
      expect(sourceContent).toContain('greet');
      
      // Should have written README
      const readme = mockAdapter.fs.getWrittenContent('README.md');
      expect(readme).toBeDefined();
    });

    it('should analyze existing codebase when path provided', async () => {
      // Seed existing files
      mockAdapter.fs.seedFile('existing/src/utils.ts', `
export function helper(): string {
  return 'helper';
}
`);

      await engine.run('Extend the existing project', 'existing');

      // LLM should have been called with context
      const architectCall = mockAdapter.llm.calls.generate.find(
        c => c.systemPrompt.includes('Lead System Architect')
      );
      expect(architectCall?.userPrompt).toContain('existing');
    });

    it('should emit events during execution', async () => {
      const phases: string[] = [];
      
      engine.events.on('phase:start', async (e) => {
        phases.push(e.data.phase as string);
      });

      await engine.run('Create a module');

      expect(phases).toContain('context-gathering');
      expect(phases).toContain('planning');
      expect(phases).toContain('execution');
      expect(phases).toContain('documentation');
    });

    it('should track progress during execution', async () => {
      // Progress tracking happens through events, which the ProgressTracker listens to
      // We can verify the engine exposes progress information
      await engine.run('Create a module');

      // After completion, progress should reflect the run completed
      const finalProgress = engine.progress.getProgress();
      // Phase could be 'completed' or 'documentation' depending on timing
      expect(['completed', 'documentation']).toContain(finalProgress.phase);
    });
  });

  describe('error handling', () => {
    it('should retry on test failure', async () => {
      let attemptCount = 0;
      
      // Configure LLM to respond to fixer requests
      mockAdapter.llm.addPromptMatch('Debugging Specialist', `
export function greet(name: string): string {
  return \`Hello, \${name}!\`;
}

export function add(a: number, b: number): number {
  return a + b;  // Fixed!
}
`);

      // Override test runner to fail first, then pass
      const originalRunner = mockAdapter.shell.getTestRunner();
      const mockRunner = {
        ...originalRunner,
        name: 'mock-jest',
        async run(testFile: string) {
          attemptCount++;
          if (attemptCount === 1) {
            return {
              passed: false,
              numPassed: 0,
              numFailed: 1,
              numSkipped: 0,
              failures: [{ testName: 'should work', message: 'Expected 5 got 4' }],
              duration: 100,
              rawOutput: 'FAIL: Expected 5 got 4'
            };
          }
          return {
            passed: true,
            numPassed: 2,
            numFailed: 0,
            numSkipped: 0,
            failures: [],
            duration: 100,
            rawOutput: 'PASS'
          };
        },
        async isAvailable() { return true; }
      };
      
      mockAdapter.shell.getTestRunner = () => mockRunner;

      await engine.run('Create a module with retry');

      // Should have called test runner at least twice (fail + pass)
      expect(attemptCount).toBeGreaterThanOrEqual(2);
    });

    it('should fail gracefully after max retries', async () => {
      // Always fail tests
      mockAdapter.shell.setTestResult('src/main.test.ts', {
        passed: false,
        numFailed: 1,
        failures: [{ testName: 'test', message: 'Persistent failure' }],
        rawOutput: 'FAIL: Persistent failure'
      });

      // Override shell to always fail
      mockAdapter.shell.exec = async () => ({
        stdout: '',
        stderr: 'FAIL: Persistent failure',
        exitCode: 1
      });

      // Add fixer response (won't fix the issue)
      mockAdapter.llm.addPromptMatch('Debugging Specialist', `
export function broken(): void {}
`);

      await expect(engine.run('Create a module')).rejects.toThrow();
    });
  });

  describe('dependency handling', () => {
    it('should execute tasks in dependency order', async () => {
      // Reset and reconfigure for this specific test
      mockAdapter.reset();
      
      // Configure multi-file plan
      mockAdapter.llm.addPromptMatch('Lead System Architect', JSON.stringify({
        architecture_reasoning: 'Layered architecture',
        tasks: [
          { id: 'types', file_path: 'src/types.ts', description: 'Type definitions', dependencies: [], type: 'code' },
          { id: 'utils', file_path: 'src/utils.ts', description: 'Utilities', dependencies: ['types'], type: 'code' },
          { id: 'main', file_path: 'src/main.ts', description: 'Main module', dependencies: ['utils'], type: 'code' }
        ]
      }));
      
      // Add builder and scribe responses
      mockAdapter.llm.addPromptMatch('Senior TypeScript Developer', 'export const x = 1;');
      mockAdapter.llm.addPromptMatch('Technical Writer', '# README');
      mockAdapter.shell.setTestResult('src/types.test.ts', { passed: true });
      mockAdapter.shell.setTestResult('src/utils.test.ts', { passed: true });
      mockAdapter.shell.setTestResult('src/main.test.ts', { passed: true });

      await engine.run('Create a layered module');

      // Verify source files were written
      const filesWritten = mockAdapter.fs.calls.writeFile.map(w => w.path);
      
      // Should have written all source files (note: tests are also written)
      expect(filesWritten).toContain('src/types.ts');
      expect(filesWritten).toContain('src/utils.ts');
      expect(filesWritten).toContain('src/main.ts');
    });
  });

  describe('context building', () => {
    it('should pass interface context to dependent tasks', async () => {
      // Reset and reconfigure for this specific test
      mockAdapter.reset();
      
      // Configure plan with dependencies
      mockAdapter.llm.addPromptMatch('Lead System Architect', JSON.stringify({
        architecture_reasoning: 'Test',
        tasks: [
          { id: 'base', file_path: 'src/base.ts', description: 'Base interface', dependencies: [], type: 'code' },
          { id: 'impl', file_path: 'src/impl.ts', description: 'Implementation', dependencies: ['base'], type: 'code' }
        ]
      }));
      
      // Add builder and scribe responses
      mockAdapter.llm.addPromptMatch('Senior TypeScript Developer', 'export interface Base {}');
      mockAdapter.llm.addPromptMatch('Technical Writer', '# README');
      mockAdapter.shell.setTestResult('src/base.test.ts', { passed: true });
      mockAdapter.shell.setTestResult('src/impl.test.ts', { passed: true });

      await engine.run('Create with interfaces');

      // Verify both files were written
      const filesWritten = mockAdapter.fs.calls.writeFile.map(w => w.path);
      expect(filesWritten).toContain('src/base.ts');
      expect(filesWritten).toContain('src/impl.ts');
      
      // Verify LLM was called for building both files
      const builderCalls = mockAdapter.llm.calls.generate.filter(
        c => c.systemPrompt.includes('Senior TypeScript Developer')
      );
      expect(builderCalls.length).toBeGreaterThanOrEqual(2);
    });
  });
});

describe('DevEngine with checkpointing', () => {
  let mockAdapter: MockEnvironmentAdapter;

  beforeEach(() => {
    mockAdapter = createMockAdapter();
    
    // Setup basic LLM responses
    mockAdapter.llm.addPromptMatch('Lead System Architect', JSON.stringify({
      architecture_reasoning: 'Test',
      tasks: [
        { id: 'task1', file_path: 'src/a.ts', description: 'Task 1', dependencies: [], type: 'code' }
      ]
    }));
    mockAdapter.llm.addPromptMatch('Senior TypeScript Developer', 'export const a = 1;');
    mockAdapter.llm.addPromptMatch('Technical Writer', '# README');
    mockAdapter.shell.setTestResult('src/a.test.ts', { passed: true });
  });

  it('should save checkpoints during execution', async () => {
    const engine = new DevEngine(mockAdapter, {
      enableCheckpoints: true,
      checkpointDir: '.test/state'
    });

    await engine.run('Test with checkpoints');

    // Should have written state file
    const stateFiles = mockAdapter.fs.calls.writeFile.filter(
      w => w.path.includes('.test/state')
    );
    expect(stateFiles.length).toBeGreaterThan(0);
  });

  it('should emit checkpoint events', async () => {
    const engine = new DevEngine(mockAdapter, {
      enableCheckpoints: true
    });

    const checkpointEvents: unknown[] = [];
    engine.events.on('checkpoint:saved', async (e) => { 
      checkpointEvents.push(e.data); 
    });

    await engine.run('Test checkpoints');

    expect(checkpointEvents.length).toBeGreaterThan(0);
  });
});
